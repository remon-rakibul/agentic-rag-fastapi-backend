# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL connection string
# Format: postgresql://username:password@host:port/database
DATABASE_URL=postgresql://postgres:your_password@localhost:5432/rag_pipeline

# Vector store table name (default: data)
VECTOR_STORE_TABLE_NAME=data

# =============================================================================
# OpenAI Configuration
# =============================================================================
# OpenAI API key for embeddings and LLM
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-your-openai-api-key-here

# =============================================================================
# Authentication Configuration
# =============================================================================
# Secret key for JWT token signing (CHANGE THIS IN PRODUCTION!)
# Generate a secure key with: openssl rand -hex 32
SECRET_KEY=your-secret-key-change-in-production

# JWT algorithm (default: HS256)
ALGORITHM=HS256

# JWT token expiration time in minutes (default: 30)
ACCESS_TOKEN_EXPIRE_MINUTES=30

# =============================================================================
# File Upload Configuration
# =============================================================================
# Maximum file upload size in bytes (default: 100MB)
MAX_UPLOAD_SIZE=104857600

# Directory for temporary file uploads (default: /tmp/rag_uploads)
UPLOAD_DIR=/tmp/rag_uploads

# =============================================================================
# Application Configuration
# =============================================================================
# Application name
APP_NAME=RAG Pipeline API

# Application version
APP_VERSION=1.0.0

# Debug mode (true/false) - NEVER enable in production!
DEBUG=false

# =============================================================================
# Web Scraping Configuration
# =============================================================================
# User agent for web scraping (optional but recommended)
USER_AGENT=RAG-Pipeline-Bot/1.0

# =============================================================================
# Docker-Specific Configuration (when using docker-compose)
# =============================================================================
# When running with docker-compose, use the service name as host
# DATABASE_URL=postgresql://postgres:123456@db:5432/postgres

# =============================================================================
# Production Recommendations
# =============================================================================
# 1. Generate a strong SECRET_KEY:
#    openssl rand -hex 32
#
# 2. Use environment-specific .env files:
#    - .env.development
#    - .env.staging
#    - .env.production
#
# 3. Never commit .env files to version control
#
# 4. Set DEBUG=false in production
#
# 5. Use strong database passwords
#
# 6. Restrict CORS origins in production (app/main.py)
#
# 7. Enable HTTPS in production
#
# 8. Consider using a secrets management service:
#    - AWS Secrets Manager
#    - HashiCorp Vault
#    - Azure Key Vault

# =============================================================================
# Web Search Configuration
# =============================================================================
# Tavily API key for web search functionality (optional)
# Get your key from: https://tavily.com/
# When configured, the LLM can search the internet for current information
TAVILY_API_KEY=tvly-dev-your-tavily-api-key-here
